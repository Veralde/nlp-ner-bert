{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daaZnXpThX_w"
      },
      "outputs": [],
      "source": [
        "import torch, subprocess, os, textwrap\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
        "!nvidia-smi -L  # should list a GPU if you got one\n",
        "\n",
        "!pip install -q seqeval\n",
        "\n",
        "import itertools, pandas as pd\n",
        "\n",
        "def read_conll(path):\n",
        "    \"\"\"Reads CoNLL file -> list[ list[str] ], list[ list[str] ]\"\"\"\n",
        "    sents, labels, tokens, tags = [], [], [], []\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith(\"-DOCSTART-\"):\n",
        "                if tokens:\n",
        "                    sents.append(tokens); labels.append(tags)\n",
        "                    tokens, tags = [], []\n",
        "                continue\n",
        "            token, tag = line.split()[0], line.split()[-1]\n",
        "            tokens.append(token); tags.append(tag)\n",
        "    if tokens:                      # last sentence\n",
        "        sents.append(tokens); labels.append(tags)\n",
        "    return sents, labels\n",
        "\n",
        "train_s, train_l = read_conll(\"/content/train.txt\")\n",
        "val_s,   val_l   = read_conll(\"/content/valid.txt\")\n",
        "test_s,  test_l  = read_conll(\"/content/test.txt\")\n",
        "\n",
        "print(\"Train:\", len(train_s), \"Val:\", len(val_s), \"Test:\", len(test_s))\n",
        "\n",
        "\n",
        "\n",
        "unique_tags = sorted({t for seq in itertools.chain(train_l, val_l, test_l) for t in seq})\n",
        "id2tag      = {i:t for i,t in enumerate(unique_tags)}\n",
        "tag2id      = {t:i for i,t in id2tag.items()}\n",
        "num_labels  = len(unique_tags)\n",
        "print(\"Labels:\", unique_tags)\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "def encode(sentences, labels):\n",
        "    encodings = tokenizer(\n",
        "        sentences,                  # list[list[str]]\n",
        "        is_split_into_words=True,\n",
        "        return_offsets_mapping=True,\n",
        "        truncation=True,\n",
        "        padding=True\n",
        "    )\n",
        "    encoded_labels = []\n",
        "    for i, offsets in enumerate(encodings.pop(\"offset_mapping\")):\n",
        "        word_ids = encodings.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        prev_word = None\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_id != prev_word:\n",
        "                label_ids.append(tag2id[ labels[i][word_id] ])\n",
        "                prev_word = word_id\n",
        "            else:                       # sub-token of same word\n",
        "                label_ids.append(-100)\n",
        "        encoded_labels.append(label_ids)\n",
        "    encodings[\"labels\"] = encoded_labels\n",
        "    return encodings\n",
        "\n",
        "train_enc = encode(train_s, train_l)\n",
        "val_enc   = encode(val_s,   val_l)\n",
        "test_enc  = encode(test_s,  test_l)\n",
        "\n",
        "\n",
        "import torch\n",
        "class NERDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, enc): self.enc = enc\n",
        "    def __len__(self):       return len(self.enc[\"input_ids\"])\n",
        "    def __getitem__(self, i):\n",
        "        return {k: torch.tensor(v[i]) for k,v in self.enc.items()}\n",
        "\n",
        "train_ds, val_ds, test_ds = map(NERDataset, [train_enc, val_enc, test_enc])\n",
        "\n",
        "\n",
        "from transformers import AutoModelForTokenClassification\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2tag,\n",
        "    label2id=tag2id\n",
        ")\n",
        "\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "def metrics_fn(pred):\n",
        "    logits, labels = pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    true_tags, pred_tags = [], []\n",
        "    for p, l in zip(preds, labels):\n",
        "        seq_true, seq_pred = [], []\n",
        "        for pi, li in zip(p, l):\n",
        "            if li == -100:             # ignore sub-tokens / padding\n",
        "                continue\n",
        "            seq_true.append(id2tag[li])\n",
        "            seq_pred.append(id2tag[pi])\n",
        "        true_tags.append(seq_true)\n",
        "        pred_tags.append(seq_pred)\n",
        "    return {\n",
        "        \"precision\": precision_score(true_tags, pred_tags),\n",
        "        \"recall\":    recall_score(true_tags, pred_tags),\n",
        "        \"f1\":        f1_score(true_tags, pred_tags)\n",
        "    }\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir          = \"ner_modelV3\",\n",
        "    eval_strategy       = \"steps\",\n",
        "    save_strategy       = \"steps\",\n",
        "    learning_rate       = 6e-6,\n",
        "    per_device_train_batch_size = 16,\n",
        "    per_device_eval_batch_size  = 16,\n",
        "    num_train_epochs    = 5,\n",
        "    weight_decay        = 0.01,\n",
        "    logging_steps       = 100,\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = \"f1\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model           = model,\n",
        "    args            = args,\n",
        "    train_dataset   = train_ds,\n",
        "    eval_dataset    = val_ds,\n",
        "    compute_metrics = metrics_fn,\n",
        "    tokenizer       = tokenizer\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "metrics = trainer.evaluate(test_ds)\n",
        "print(metrics)\n",
        "\n",
        "\n",
        "pred_logits = trainer.predict(test_ds).predictions\n",
        "pred_ids    = np.argmax(pred_logits, axis=-1)\n",
        "\n",
        "true_tags, pred_tags = [], []\n",
        "for p, l in zip(pred_ids, test_enc[\"labels\"]):\n",
        "    t_seq, p_seq = [], []\n",
        "    for pi, li in zip(p, l):\n",
        "        if li == -100: continue\n",
        "        t_seq.append(id2tag[li]); p_seq.append(id2tag[pi])\n",
        "    true_tags.append(t_seq); pred_tags.append(p_seq)\n",
        "\n",
        "print(classification_report(true_tags, pred_tags))\n",
        "\n",
        "\n",
        "trainer.save_model(\"/content/ner_bert_NLPv3\")\n",
        "tokenizer.save_pretrained(\"/content/ner_bert_NLPv3\")\n",
        "\n",
        "\n",
        "import shutil, pathlib, zipfile\n",
        "\n",
        "ckpt_dir = pathlib.Path(\"/content/ner_bert_NLPv3\")\n",
        "zip_path = \"/content/ner_bert_NLPv3.zip\"\n",
        "\n",
        "shutil.make_archive(base_name=zip_path.replace(\".zip\",\"\"),\n",
        "                    format=\"zip\",\n",
        "                    root_dir=ckpt_dir)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(zip_path)        # Tarayıcınıza iner\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch, numpy as np\n",
        "\n",
        "model_dir = \"/content/ner_bert_NLPv3\"   # ya da indirdiğiniz zip’i açtığınız yer\n",
        "tok  = AutoTokenizer.from_pretrained(model_dir)\n",
        "ner  = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
        "\n",
        "sentence = \"Donald Trump and Donald Duck is an amazing person who works at Facebook and Google at California\"\n",
        "tokens   = tok(sentence, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    logits = ner(**tokens).logits\n",
        "pred_ids = logits.argmax(-1).squeeze().tolist()\n",
        "\n",
        "for sub_tok, tag_id in zip(tok.tokenize(sentence), pred_ids[1:-1]):  # CLS-SEP hariç\n",
        "    tag = ner.config.id2label[tag_id]\n",
        "    print(f\"{sub_tok:12} → {tag}\")\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1) Numeric Results\n",
        "val_metrics = trainer.evaluate(val_ds)\n",
        "test_metrics = trainer.evaluate(test_ds)\n",
        "\n",
        "print(\"Validation Metrics:\")\n",
        "for k, v in val_metrics.items():\n",
        "    if k.startswith(\"eval_\"):\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "print(\"\\nTest Metrics:\")\n",
        "for k, v in test_metrics.items():\n",
        "    if k.startswith(\"eval_\"):\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "# 2) Visual Results from log_history\n",
        "history = pd.DataFrame(trainer.state.log_history)\n",
        "\n",
        "# a) Train & Eval loss vs step\n",
        "train_loss_df = history[['step', 'loss']].dropna()\n",
        "eval_df       = history[['step', 'eval_loss', 'eval_precision', 'eval_recall', 'eval_f1']].dropna()\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=200)\n",
        "plt.plot(train_loss_df['step'], train_loss_df['loss'], label='train_loss', linewidth=1.5)\n",
        "plt.plot(eval_df['step'],       eval_df['eval_loss'], label='eval_loss',  linewidth=1.5)\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training & Evaluation Loss vs. Step')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# b) Precision / Recall / F1 vs step\n",
        "plt.figure(figsize=(10, 6), dpi=200)\n",
        "plt.plot(eval_df['step'], eval_df['eval_precision'], marker='o', label='Precision')\n",
        "plt.plot(eval_df['step'], eval_df['eval_recall'],    marker='o', label='Recall')\n",
        "plt.plot(eval_df['step'], eval_df['eval_f1'],        marker='o', label='F1-score')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Evaluation Metrics vs. Step')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# c) Final-step bar chart\n",
        "final_step = eval_df['step'].max()\n",
        "final_row  = eval_df[eval_df['step'] == final_step].iloc[0]\n",
        "final_scores = {\n",
        "    'Precision': final_row['eval_precision'],\n",
        "    'Recall':    final_row['eval_recall'],\n",
        "    'F1-score':  final_row['eval_f1']\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(8, 5), dpi=200)\n",
        "bars = plt.bar(final_scores.keys(), final_scores.values())\n",
        "for bar, score in zip(bars, final_scores.values()):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, score + 0.01,\n",
        "             f\"{score:.3f}\", ha='center')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.title(f\"Final Metrics at Step {int(final_step)}\")\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}